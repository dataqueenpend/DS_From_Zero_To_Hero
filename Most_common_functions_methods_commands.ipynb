{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Most common functions-methods-commands.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORhc6epqtOrlw2RVd0DTlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataqueenpend/DS_From_Zero_To_Hero/blob/gh-pages/Most_common_functions_methods_commands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64YMe-6zlbNI"
      },
      "source": [
        " if in trouble, go to https:\n",
        " * [Python]('https://www.w3schools.com/python/default.asp')\n",
        " * [Pandas]('https://pandas.pydata.org/docs/user_guide/index.html')\n",
        " * [Matplotlib]('https://matplotlib.org/stable/gallery/index.html')\n",
        " * [Seaborn]('https://seaborn.pydata.org/api.html')\n",
        " * [SciPy]('https://docs.scipy.org/doc/scipy/tutorial/index.html')\n",
        "\n",
        "##Useful tricks, that can be used almost in any case\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ay94Ul0lk8A"
      },
      "source": [
        "#Swapping the values of the variable\n",
        "a,b = b,a #The values stored in var a is stored in var b, the value of var b is stored in var a\n",
        "a[1],a[-1] = a[-1],a[1] #Swapping values in a list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xztjO8izIVUQ"
      },
      "source": [
        "## Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViK_tKqIf0i"
      },
      "source": [
        "thisdict = {\n",
        "  \"brand\": \"Ford\",\n",
        "  \"model\": \"Mustang\",\n",
        "  \"year\": 1964\n",
        "}\n",
        "\n",
        "#Values\n",
        "thisdict[\"year\"] = 2018 #Changes dictionary values\n",
        "thisdict.update({\"year\": 2020}) #Changes the dictionary values with .update() method\n",
        "x = thisdict[\"model\"] #Access dicionary value\n",
        "x = thisdict.get(\"model\") #Access dictionary values with .get\n",
        "x = thisdict.values() #Prints the values of the dictionary\n",
        "\n",
        "#Keys\n",
        "x = thisdict.keys() #Prints the keys of the dictionary\n",
        "\n",
        "#Key&values\n",
        "x = thisdict.items() #Prints the keys and values of the dictionary in key:value order\n",
        "thisdict.update({\"color\": \"red\"}) # Adds new key:value pair into dictionary with.update() method\n",
        "thisdict.pop(\"model\") #Removes the item with a specific key\n",
        "del thisdict[\"model\"] #Removes the item with a specific key\n",
        "thisdict.popitem() #Removes last item in the dictionary\n",
        "\n",
        "thisdict.clear() #Empties a dictionary\n",
        "del thisdict #Deletes the whole dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez634k1cUoWy"
      },
      "source": [
        "## List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeOrh2TcUsEI"
      },
      "source": [
        "thislist = [\"apple\", \"banana\", \"cherry\"]\n",
        "\n",
        "len(thislist) #Checks the number of the elements in the list\n",
        "\n",
        "thislist[1] #Access list elements - through index\n",
        "thislist[2:5] #Slices the list - access elements in a range\n",
        "thislist[1] = \"blackcurrant\" #Changes/Adds the element of the list through index\n",
        "thislist[1:3] = [\"blackcurrant\", \"watermelon\"] #Changes the elements of the list in range\n",
        "\n",
        "sorted(thislist)#Sorted gives a new sorted list\n",
        "thislist.sort()#Sort, sorts an existing list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C1i9ufAneGQ"
      },
      "source": [
        "## Boolean\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6ZZpy-F2Hz"
      },
      "source": [
        "## DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leb3ihCxF62x"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "#Importing files with Pandas\n",
        "#Read csv from url\n",
        "url = \"https://url.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#DataFrame EDA\n",
        "df.shape #Calculates number of rows and columns of the DataFrame\n",
        "df.columns #Shows column names of the DataFrame in a index data structure - similar to a list\n",
        "df['col_name'].value_counts().sort_index() #Calcutes the number of values in selected DataFrame (and sorts from highest to the lowest)\n",
        "df['col_name'].describe() #Calculates common used statistics for the selected column in the DataFrame\n",
        "\n",
        "#Cleaning the DataFrame\n",
        "new_var = df.dropna(subset['col_name1', 'col_name2']) #Dropps NAN rows and subset the DataFrame, in this case selects two columns, stors it in a new variable\n",
        "\n",
        "#Manipulating the DataFrame\n",
        "col_sel = df['col_name'] #Selects DataFrame column -> returns Pandas Series\n",
        "DF[(DF[\"COL_NAME\"]=='ROW') | (DF[\"COL_NAME\"]=='ROW')] #Selects specific rows from the df \n",
        "df['col_name'].replace([0, 1], np.nan) #Replaces selected values (can be stored in a list) with other values (can be nan)\n",
        "df.groupby('col_name') #Groups by col_name in the DataFrame, returns Groupby objects (acts similar to the DataFrame)\n",
        "\n",
        "#Filtering the DataFrame\n",
        "df['col_name'] >= 37 #Filters the selected column with a comparison operator (==, !=, <, >, <=, >=)\n",
        "new_var = (col_name >=14) & (col_name <16) #Filters variable/column of the DataFrame with a multiple comparison operators\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZMt4N_XCQUf"
      },
      "source": [
        "## NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIWP2_OvCSRO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Creating an arrays\n",
        "np.empty() #Creates an array without initializing the entries of given shape and type. \n",
        "\n",
        "#Array operations\n",
        "np.concatenate() #Concats number of arrays. Takes a tuple of arrays for concatenation.\n",
        "\n",
        "#Random functions\n",
        "np.random.permutation() #Randomly scrables the data ine the array\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kxsz-4vyt68"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zvmiCJgyyR1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Visualization for numerical data type\n",
        "#Histogram\n",
        "plt.hist(var_name_of_selected_col/df['col_name'/numpy array], bins=20, histtype='step') #Histogram - best for discrete, continous data and large datasets\n",
        "\n",
        "#Barchart\n",
        "plt.bar(var_name_of_selected_col, )\n",
        "\n",
        "#Scatter plot\n",
        "plt.plot(df, 'o', alpha=0.2) #Alternative way o creating scatter plot(faster) - best for checking if there is a relation between two numerical variables\n",
        "\n",
        "\n",
        "#Bin edges on integers \n",
        "# Compute bin edges: bins\n",
        "bins = np.arange(0, max(n_defaults) + 1.5) - 0.5\n",
        "# Generate histogram\n",
        "plt.hist(n_defaults, bins=bins, normed=True)\n",
        "\n",
        "\n",
        "#Label the axes\n",
        "plt.xlabel('col_name1') \n",
        "plt.ylabel('col_name2')\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qck17GM4xzNV"
      },
      "source": [
        "## Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vfmpGCx1Je"
      },
      "source": [
        "import seaborn as sns\n",
        "#Type help(name_of_the_plot) for more info about the plot\n",
        "help(sns.swarmplot)\n",
        "\n",
        "#Line Plot\n",
        "sns.lineplot(data=df, x='col_name1', y='col_name2') #Plots line plot\n",
        "\n",
        "#Dist Plot \n",
        "sns.distplot(df['col_name'], kde=False, bins=10) #Plots distplot which is similar to the matplotlib histogram\n",
        "\n",
        "#Swarm Plot\n",
        "sns.swarmplot(x='var_on_x_axes', y='var_on_y_axes', data=df) #Plots Swarm Plot, data = df/sliced df\n",
        "\n",
        "#Box Plot\n",
        "sns.boxplot(x='var_on_x_axes', y='var_on_y_axes', data=df) #Plots Box Plot, data = df/sliced df - if the swarm plot gets cluttered \n",
        "\n",
        "#Violin Plot\n",
        "sns.violinplot(x='var_on_x_axes', y='var_on_y_axes', data=df) #Plots Violin Plot, data = df/sliced df\n",
        "\n",
        "#KDE Plot\n",
        "sns.kdeplot(data=df, x=\"\") #Plots KDE plot, optional x argument if series object, data = df/series object\n",
        "\n",
        "#Point Plot\n",
        "sns.pointplot(data=df, y=\"DRG Definition\", x=\"Average Covered Charges\", hue=\"Region\")\n",
        "\n",
        "\n",
        "#FacetGrid\n",
        "sns.FacetGrid(tips, col=\"name\", row=\"name\") #Plots empty facet grid\n",
        "\n",
        "g = sns.FacetGrid(tips, col=\"time\",  row=\"sex\") #Initializes Facet Grid\n",
        "g.map(sns.scatterplot, \"total_bill\", \"tip\") #Mapps Facet Grid\n",
        "g.set_axis_labels(\"Total bill\", \"Count\") #Labels for Facet Grid axes\n",
        "\n",
        "\n",
        "#Add vertical line\n",
        "plt.axvline(50, color='green') #Adds a vertical line in desired color at the middle of x axes\n",
        "#Apply log transformation into the data\n",
        "ax.set_yscale(\"log\")\n",
        "#Set x_ticks\n",
        "ax.set_xticks(xticks) #In the parantheses is a variable in which we store the position of x-ticks\n",
        "#Set margins\n",
        "plt.margins(0.02)\n",
        "#Height of the bars of the histogram is equal to one\n",
        "_ = plt.hist(normed=True)\n",
        "\n",
        "#Shared axes\n",
        "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True) #sharey=True\n",
        "sns.distplot(avocado.query('region == \"NewYork\"')['AveragePrice'], ax=ax0) #ax=ax0\n",
        "sns.distplot(avocado.query('region == \"Philadelphia\"')['AveragePrice'], ax=ax1) #ax=ax1\n",
        "\n",
        "#Show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSqliIDVDbbY"
      },
      "source": [
        "## Statistics \n",
        "\n",
        "Use **CDF**s for exploration.\n",
        "\n",
        "Use **PMF**s if there are a small number of unique values.\n",
        "\n",
        "Use **ECDF**s allows you to plot a feature of your data in order from least to greatest and see the whole feature as if is distributed across the data set. It is build on **empirical** data.\n",
        "\n",
        "Use **KDE** if there are a lot of values.\n",
        "\n",
        "Use **Logistic Regression** if the data is categorical (each respondent belongs to one of a specified set of categories).\n",
        "\n",
        "\n",
        "* Can't measure non linear relationships:\n",
        "  * Use **Correlation** if you want to see if there is relathionship between the variables. \n",
        "\n",
        "  * Use **Simple Regression** if"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HooKHLlvDmDL"
      },
      "source": [
        "only_columns.corr() #Calculates the correlation between the subsetted columns stored in the variables only_columns\n",
        "linregress(xs,ys) #Calculates simple regression between xs and ys (subsetted columns with dropped NAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejcw5G0_zZH7"
      },
      "source": [
        "#ECDF function - for future use(can be use to compute the CDF also, but the data input should contain theorethical data, not the real data)\n",
        "def ecdf(data):\n",
        "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
        "    # Number of data points: n\n",
        "    n = len(data)\n",
        "\n",
        "    # x-data for the ECDF: x\n",
        "    x = np.sort(data)\n",
        "\n",
        "    # y-data for the ECDF: y\n",
        "    y = np.arange(1, n+1) / n\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxmKOSDrXV90"
      },
      "source": [
        "#Making ECDF\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "x = np.sort(df['col_name'])\n",
        "y = np.arange(1, len(x)+1) / len(x)\n",
        "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
        "_ = plt.xlabel('label_x')\n",
        "_ = plt.ylabel('ECDF')\n",
        "plt.margins(0.02) # Keeps data off plot edges\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVo3WSYgmIWf"
      },
      "source": [
        "Simple **summary statistics**\n",
        "\n",
        "* **Variance** - how much a set of observation differs from each other.\n",
        "* **Covariance** - (+/-)  positives value indicate that two variable moves in the same direction / negative values show that two variable moves in the inverse direction.\n",
        "* **Standard Deviation** - measures the dispersion of a dataset relative to its mean.\n",
        "  * SEM - **standard error of the mean** - Under not-too-restrictive conditions, the value of the mean will always be Normally distributed. Caculates given by the standard deviation of the data divided by the square root of the number of data points. ```sem = np.std(data) / np.sqrt(len(data))```\n",
        "* **Pearson correlation coefficient** - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xz9vW_mRHg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.mean('column_name') #Calculates the average\n",
        "np.median('column_name') #Calculates the median - middle value of the dataset (data needs to be sorted)\n",
        "np.percentile(df['col_name'], [25, 50, 75]) #Calculates the percentiles of the given numbers store in a list\n",
        "np.var(df['col_name']) #Calculates the variance - average of the squared distance from the mean (square the distance from the mean, and then take the average of all of these values)\n",
        "np.std(df['col_name']) #Calculates the standard deviation - the square root of the variance \n",
        "np.cov(x, y) #Calculates covariance for two sets (x,y) of variables. Returns an 2darray - covariance matrix, in which one array stores variance of the first dataset, second array stores variance of the second dataset. Together they create covariance matrix.\n",
        "np.corrcoef(x, y) # Calculates pearson correlation coefficient (x,y)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLpmQnFo8E63"
      },
      "source": [
        "#Function pearson correlation coefficient\n",
        "def pearson_r(x, y):\n",
        "    \"\"\"Compute Pearson correlation coefficient between two arrays.\"\"\"\n",
        "    # Compute correlation matrix: corr_mat\n",
        "    corr_mat = np.corrcoef(x,y)\n",
        " \n",
        " \n",
        "    # Return entry [0,1]\n",
        "    return corr_mat[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMnyfoB7WRI7"
      },
      "source": [
        "## Hacker Statistics\n",
        " For discrete variables:\n",
        "* **Binomial distribution** - \n",
        "* **Poissson distribution** - the Poisson distribution is a limit of the Binomial distribution for rare events. Events in poisson the distribution don't have a time-relationship between themselves. They occur randomly - like child births/aviation catastrophes etc. \n",
        " \n",
        " \n",
        " For continous variables:\n",
        "* **Normal(gaussian) distribution** - \n",
        "* **Exponential distribution** - describes the waiting times between rare events.\n",
        "\n",
        "\n",
        "Regression:\n",
        "* **Least squares** - can be computed with **np.polyfit()**, the process of finding the parameters for which the sum of the squares of the residuals is minimal. Residuals - points away from the line. Slope - slope of the line. Intercept - point of y axes intercept. \n",
        "  * Regression equation```y = a*x + b```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rKlxnH2WUUq"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed() #Function that allows to reproduce random calculations. Takes a numerical value as an argument. It is not advisible to use anymore. \n",
        "\n",
        "np.random.random() #Generates a random number between 0 and 1. Size the number of generated number by passing argument size = any number.\n",
        "np.random.binomial(n,p) #Draw samples from a binomial distribution (takes two arguments n(Parameter of the distribution  >= 0) and p(Parameter of the distribution, >= 0 and <=1), and optional size) \n",
        "np.random.poisson(10, size=10000) #Draw samples from poisson distribution (1st arg = mean, 2nd arg= size of the sample )\n",
        "\n",
        "np.random.normal(mean, std, size=) #Drwa samples from normal distribution (takes values as arguments for mean, std and size)\n",
        "np.random.exponential() #Drwa samples from an exponential distribution (takes single parameter - the typical interval time of the events occurance(the mean interval time))\n",
        "\n",
        "\n",
        "#Regression line\n",
        "np.polyfit(total_votes, dem_share, 1) #Computing least squares. Takes x,y data, and the degree of polynomial. Linear functions - 1. Returns slope and intercept of the best fit line."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z38nLZ3gHkkF"
      },
      "source": [
        "## Bootstraping \n",
        "**Bootstrapping** - the use of resampled data to perform statistical inference. With bootstraping we can answear a question: what would happen if we could repeat the data acquisition an infinite number of times. Can we **use only the data we** actually **have to get close to the same result as an infinitude of experiments**? Yes. With bootraping technique.\n",
        "\n",
        "* **Bootstrap sample** - a resampled array of the data\n",
        "* **Bootstrap replicate** - a statistic computed from a resampled array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwSOJaz9ITqz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Resampling engine: np.random.choice()\n",
        "np.random.choice([1,2,3,4,5], size=5) \n",
        "\n",
        "#Computing a bootstrap replicate\n",
        "bs_sample = np.random.choice(michelson_speed_of_light,size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZPC9f2Yu8l2"
      },
      "source": [
        "#Bootstrap replicate function\n",
        "def bootstrap_replicate_1d(data, func): #Replicates a given data and calculates a desired function\n",
        "  \"\"\"Generate bootstrap replicate of 1D data.\"\"\"\n",
        "  bs_sample = np.random.choice(data, len(data))\n",
        "  return func(bs_sample)\n",
        "\n",
        "#For many replicates\n",
        "def bootstrap_many_replicates(data, func,size = 1):\n",
        "  bs_replicates = np.empty(size)\n",
        "  for i in range(size):\n",
        "    bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
        "  return bs_replicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICLHo4R3xdoU"
      },
      "source": [
        "### Confidence interval of a statistic\n",
        "Confidence intervals gives **upper and lower bounds on the range of parameter values you might expect to get if we repeat our measurements**. \n",
        "\n",
        "If we repeated measurements over and over again, p% of the observed values would lie within the p% confidence interval.\n",
        "\n",
        "We can calculate them by taking a percentiles of the bootstrap replicates with ```np.percentile()```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_h5bCRg7-IJ"
      },
      "source": [
        "np.percentile(data, [2.5, 97.5]) #Returns the 95% confidence interval of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3TcrLiXCqy4"
      },
      "source": [
        "###Pairs bootstrap for linear regression\n",
        "Resample data in pairs, compute confdence intervals from percentiles of bootstrap replicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ7Hi-KODans"
      },
      "source": [
        "#Generating a pairs bootstrap sample\n",
        "inds = np.arange(len(total_votes))\n",
        "bs_inds = np.random.choice(inds, len(inds))\n",
        "bs_total_votes = total_votes[bs_inds]\n",
        "bs_dem_share = dem_share[bs_inds]\n",
        "\n",
        "#Computing a pairs bootstrap replicate\n",
        "bs_slope, bs_intercept = np.polyfit(bs_total_votes, bs_dem_share, 1)\n",
        "#Fit of original\n",
        "np.polyfit(total_votes, dem_share, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsCIkSICF6qD"
      },
      "source": [
        "#Multiple bootstrap pairs for linear regression\n",
        "def draw_bs_pairs_linreg(x, y, size=1):\n",
        "    \"\"\"Perform pairs bootstrap for linear regression.\"\"\"\n",
        "\n",
        "    # Set up array of indices to sample from: inds\n",
        "    inds = np.arange(len(x))\n",
        "\n",
        "    # Initialize replicates: bs_slope_reps, bs_intercept_reps\n",
        "    bs_slope_reps = np.empty(size)\n",
        "    bs_intercept_reps = np.empty(size)\n",
        "\n",
        "    # Generate replicates\n",
        "    for i in range(size):\n",
        "        bs_inds = np.random.choice(inds, size=len(inds))\n",
        "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
        "        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)\n",
        "\n",
        "    return bs_slope_reps, bs_intercept_reps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp6tDvePLIzD"
      },
      "source": [
        "###Hypothesis testing \n",
        "(Null hypothesis) Assessment of how reasonable the observed data are assuming a hypothesis is true.\n",
        "#### **Pipeline for hypothesis testing**\n",
        "* Clearly state the null hypothesis\n",
        "* Define your test statistic\n",
        "* Generate many sets of simulated data assuming the null\n",
        "hypothesis is true\n",
        "* Compute the test statistic for each simulated data set\n",
        "* The p-value is the fraction of your simulated data sets for\n",
        "which the test statistic is at least as extreme as for the real\n",
        "data\n",
        "\n",
        "\n",
        " Techniques:\n",
        "\n",
        "* **Permutation** - random reordering of entries in an array. Great way to simulate the hypothesis that two variables have identical probability distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad9fxafWMeqx"
      },
      "source": [
        "#Generating a permutation sample\n",
        "import numpy as np\n",
        "\n",
        "dem_share_both = np.concatenate((dem_share_PA, dem_share_OH))\n",
        "dem_share_perm = np.random.permutation(dem_share_both)\n",
        "perm_sample_PA = dem_share_perm[:len(dem_share_PA)] #Labels all the samples with a length of the first category and with a label of first category\n",
        "perm_sample_OH = dem_share_perm[len(dem_share_PA):] #Labels all the remaining data with the label of the second category\n",
        "\n",
        "#Permutation sample function\n",
        "def permutation_sample(data1, data2):\n",
        "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
        " \n",
        "    # Concatenate the data sets: data\n",
        "    data = np.concatenate((data1, data2))\n",
        " \n",
        "    # Permute the concatenated array: permuted_data\n",
        "    permuted_data = np.random.permutation(data)\n",
        " \n",
        "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
        "    perm_sample_1 = permuted_data[:len(data1)]\n",
        "    perm_sample_2 = permuted_data[len(data1):]\n",
        " \n",
        "    return perm_sample_1, perm_sample_2\n",
        "\n",
        "#Many permutation samples function\n",
        "\n",
        "def draw_perm_reps(data_1, data_2, func, size=1):\n",
        "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
        "\n",
        "    # Initialize array of replicates: perm_replicates\n",
        "    perm_replicates = np.empty(size)\n",
        "\n",
        "    for i in range(size):\n",
        "        # Generate permutation sample\n",
        "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
        "\n",
        "        # Compute the test statistic\n",
        "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
        "\n",
        "    return perm_replicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXj0wac88C_2"
      },
      "source": [
        "* **Test statistic** A single number that can be computed from observed data\n",
        "and from data you simulate under the null hypothesis. It serves as a basis of comparison between the two. \n",
        "* **p-value** The probability of obtaining a value of your test statistic that\n",
        "is at least as extreme as what was observed, under the\n",
        "assumption the null hypothesis is true. If the **p-value** is **small**, we can assume that the data is stastically significant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSfckWE1lvqo"
      },
      "source": [
        "# Compute p-value: p\n",
        "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates) #Computes p-value - sum of permutation replicates >= empiral mean of the data divided by length of permutation replicates \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}