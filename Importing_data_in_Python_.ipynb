{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Importing data in Python .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCSF06VABmudTfZ7T3YtsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataqueenpend/DS_From_Zero_To_Hero/blob/gh-pages/Importing_data_in_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y34Yky4b6M_"
      },
      "source": [
        "# **Importing Data in Python**\n",
        "\n",
        "##Importing text files\n",
        "\n",
        "Put your notes here\n",
        "\n",
        "\n",
        "\n",
        "####Exercises and examples from DataCamp\n",
        "\n",
        "**#1** Open the file moby_dick.txt as read-only and store it in the variable file. Make sure to pass the filename enclosed in quotation marks ''.\n",
        "Print the contents of the file to the shell using the print() function. As Hugo showed in the video, you'll need to apply the method read() to the object file.\n",
        "Check whether the file is closed by executing print(file.closed).\n",
        "Close the file using the close() method.\n",
        "Check again that the file is closed as you did above.\n",
        "\n",
        "```\n",
        "# Open a file: file\n",
        "filename = 'moby_dick.txt'\n",
        "file = open(filename, mode='r')\n",
        "\n",
        "# Print it\n",
        "print(file.read())\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)\n",
        "\n",
        "# Close file\n",
        "file.close()\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**#2** With larger files we it is not always the best idea to print them whole in one time. For this occasion, Python has a method called **filename()**. We can use it to print the text file line by line. See how it goes with a code example. \n",
        "\n",
        "Open moby_dick.txt using the with context manager and the variable file.\n",
        "Print the first three lines of the file to the shell by using readline() three times within the context manager.\n",
        "\n",
        "Input:\n",
        "```\n",
        "# Read & print the first 3 lines\n",
        "with open('moby_dick.txt') as file:\n",
        "    print(file.readline())\n",
        "    print(file.readline())\n",
        "    print(file.readline())\n",
        "```\n",
        "Output:\n",
        "```\n",
        "<script.py> output:\n",
        "    CHAPTER 1. Loomings.\n",
        "    \n",
        "    \n",
        "    \n",
        "    Call me Ishmael. Some years ago--never mind how long precisely--having\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Importance of flat flies in Data Science(csv files)\n",
        "\n",
        "Notes\n",
        "\n",
        "#### Examples and exercises from DataCamp\n",
        "\n",
        "\n",
        "**#1** Using Numpy to import the flatfiles\n",
        "\n",
        "In this exercise, you're now going to load the MNIST digit recognition dataset using the numpy function loadtxt() and see just how easy it can be:\n",
        "\n",
        "The first argument will be the filename.\n",
        "The second will be the delimiter which, in this case, is a comma.\n",
        "\n",
        "Fill in the arguments of np.loadtxt() by passing file and a comma ',' for the delimiter.\n",
        "Fill in the argument of print() to print the type of the object digits. Use the function type().\n",
        "Execute the rest of the code to visualize one of the rows of the data.\n",
        "```\n",
        "# Import package\n",
        "import numpy as np\n",
        "\n",
        "# Assign filename to variable: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Load file as array: digits\n",
        "digits = np.loadtxt(file, delimiter=',')\n",
        "\n",
        "# Print datatype of digits\n",
        "print(type(digits))\n",
        "\n",
        "# Select and reshape a row\n",
        "im = digits[21, 1:]\n",
        "im_sq = np.reshape(im, (28, 28))\n",
        "\n",
        "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
        "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**#2** Customizing Numpy flafile import\n",
        "\n",
        "If in the flatfile there are some rows, that you don't want to import (such as header), maybe specific columns that you don't need. Or maybe your flatfile uses different delimiter than a comma. \n",
        "\n",
        "There are solutions for above cases. Take a look:\n",
        "* **skiprow** will help you to not load the rows from the flatfile that you don't want to import\n",
        "* **usecols** will allow you to import only those columns, that you wish to have in your import\n",
        "* **delimiter** will allow you to change expected by the function delimeter - ',' <- comma delimited, '\\t' <- tab delimited\n",
        "\n",
        "Above parameters are taken in by Numpy function **np.loadtxt()**. Use them to specify your import. \n",
        "\n",
        "---\n",
        "Complete the arguments of np.loadtxt(): the file you're importing is tab-delimited, you want to skip the first row and you only want to import the first and third columns.\n",
        "Complete the argument of the print() call in order to print the entire array that you just imported.\n",
        "\n",
        "```\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'digits_header.txt'\n",
        "\n",
        "# Load the data: data\n",
        "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0,2])\n",
        "\n",
        "# Print data\n",
        "print(data)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**#3** How to deal with different datatypes?\n",
        "\n",
        "The file seaslug.txt has a text header, consisting of strings\n",
        "is tab-delimited.\n",
        "\n",
        "Due to the header, if you tried to import it as-is using np.loadtxt(), Python would throw you a ValueError and tell you that it could not convert string to float. There are two ways to deal with this: firstly, you can **set the data type argument dtype equal to str** (for string). Alternatively, **you can skip the first row** as we have seen before, using the **skiprows** argument.\n",
        "\n",
        "---\n",
        "\n",
        "Complete the first call to np.loadtxt() by passing file as the first argument.\n",
        "Execute print(data[0]) to print the first element of data.\n",
        "Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row.\n",
        "Print the 10th element of data_float by completing the print() command. Be guided by the previous print() call.\n",
        "Execute the rest of the code to visualize the data.\n",
        "\n",
        "```\n",
        "# Assign filename: file\n",
        "file = 'seaslug.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
        "\n",
        "# Print the first element of data\n",
        "print(data[0])\n",
        "\n",
        "# Import data as floats and skip the first row: data_float\n",
        "data_float = np.loadtxt(file, delimiter='\\t', dtype=float, skiprows=1)\n",
        "\n",
        "# Print the 10th element of data_float\n",
        "print(data_float[9])\n",
        "\n",
        "# Plot a scatterplot of the data\n",
        "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
        "plt.xlabel('time (min.)')\n",
        "plt.ylabel('percentage of larvae')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ocsQohMxlyW"
      },
      "source": [
        "---\n",
        "\n",
        "### Alternative way to deal with importing different data types\n",
        "\n",
        "Np.loadtxt() can be hard to work with when you will be dealing with multiple data types while importing data in Python. Another way to import files with multiple data types is to do so by using **np.genfromtxt()** . Passing to it **dtype=None** will make it to figure out what kind of data is importing to the shell.\n",
        "\n",
        "```\n",
        "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
        "```\n",
        "\n",
        "First argument of the function is csv file name, second one is delimiter, and the third one is telling the function, that we have a header here.\n",
        "\n",
        "Flat files imported with this function are stored as a 1d structed numpy arrays. This solves an issue with diffent data types - in numpy arrays all the data types are unified. **Why 1d numpy array?** In 1d numpy array each element of the array is a row from the flat file imported. \n",
        "\n",
        "Shape of the array we can check by passing **np.shape(var_name)**. How to access rows and columns of the array? Do it by just typing the name of the array and the name of the col/row you want to access. \n",
        "\n",
        "```\n",
        "data[col_or_row_name]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKVSpslO4W34"
      },
      "source": [
        "---\n",
        "#### Another way for importing mixed data type flat files into Python\n",
        "\n",
        "There is another, even simpler way for importing mixed data into Python shell. Function **np.recfromcsv()** has a default dtype set to None, so if you are using it, you don't even need to set this parameter manually. \n",
        "\n",
        "Let's try it out!\n",
        "\n",
        "Import titanic.csv using the function np.recfromcsv() and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None!\n",
        "Run the remaining code to print the first three entries of the resulting array d.\n",
        "\n",
        "Input:\n",
        "```\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Import file using np.recfromcsv: d\n",
        "d = np.recfromcsv(file, names=True, delimiter=',')\n",
        "\n",
        "# Print out first three entries of d\n",
        "print(d[:3])\n",
        "\n",
        "```\n",
        "Output:\n",
        "```\n",
        " [(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
        "     (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
        "     (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsQH9oWj5n5i"
      },
      "source": [
        "---\n",
        "### Importing flat files using Pandas\n",
        "\n",
        "Importing data using Pandas allows you to load multiple data types with no additional adjustments. Futhermore, Pandas DataFrames are just perfect for every Data Scientist needs. They are 2d labeled datastructures, with ability to store mixed types of data, are easily to manipulate, reshape, join merge etc. Perform statistics and work with time-series data. \n",
        "\n",
        "We can easily import data with Pandas with **read_csv()** and **read_table()**.\n",
        "\n",
        "---\n",
        "\n",
        "#### Examples and exercises with DataCamp\n",
        "\n",
        "**#1**\n",
        "* Import the pandas package using the alias pd.\n",
        "* Read titanic.csv into a DataFrame called df. The file name is already stored in the file object.\n",
        "* In a print() call, view the head of the DataFrame.\n",
        "\n",
        "```\n",
        "# Import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Read the file into a DataFrame: df\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# View the head of the DataFrame\n",
        "print(df.head())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYW_vD85JDXL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**#2**\n",
        "\n",
        "* Import the first 5 rows of the file into a DataFrame using the function pd.read_csv() and assign the result to data. You'll need to use the arguments nrows and header (there is no header in this file).\n",
        "* Build a numpy array from the resulting DataFrame in data and assign to data_array.\n",
        "* Execute print(type(data_array)) to print the datatype of data_array.\n",
        "\n",
        "```\n",
        "# Assign the filename: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Read the first 5 rows of the file into a DataFrame: data\n",
        "data = pd.read_csv(file, nrows=5, header=None)\n",
        "\n",
        "# Build a numpy array from the DataFrame: data_array\n",
        "data_array = np.array(data)\n",
        "\n",
        "# Print the datatype of data_array to the shell\n",
        "print(type(data_array))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRhXsqGXJoD5"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**#3** Customizing Pandas import\n",
        "\n",
        "To wrap up this chapter, you're now going to import a slightly corrupted copy of the Titanic dataset titanic_corrupt.txt, which\n",
        "\n",
        "* contains comments after the character '#'\n",
        "* is tab-delimited.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'.\n",
        "* Execute the rest of the code to print the head of the resulting DataFrame and plot the histogram of the 'Age' of passengers aboard the Titanic.\n",
        "\n",
        "```\n",
        "# Import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'titanic_corrupt.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values=['Nothing'])\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(data.head())\n",
        "\n",
        "# Plot 'Age' variable in a histogram\n",
        "pd.DataFrame.hist(data[['Age']])\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qUxUyikJsQU"
      },
      "source": [
        "## Importing pickled files and spreadsheets\n",
        "\n",
        "notes\n",
        "\n",
        "#### Exercices and examples from DataCamp\n",
        "\n",
        "**#1** \n",
        "* Import the pickle package.\n",
        "* Complete the second argument of open() so that it is read only for a binary file. This argument will be a string of two letters, one signifying 'read only', the other 'binary'.\n",
        "* Pass the correct argument to pickle.load(); it should use the variable that is bound to open.\n",
        "* Print the data, d.\n",
        "* Print the datatype of d; take your mind back to your previous use of the function type().\n",
        "\n",
        "\n",
        "```\n",
        "# Import pickle package\n",
        "\n",
        "import pickle\n",
        "# Open pickle file and load data: d\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    d = pickle.load(file)\n",
        "\n",
        "# Print d\n",
        "print(d)\n",
        "\n",
        "# Print datatype of d\n",
        "print(type(d))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXgAsTBeGBji"
      },
      "source": [
        "**#2** Here, you'll learn how to use pandas to import Excel spreadsheets and how to list the names of the sheets in any loaded .xlsx file using .sheet_names method.\n",
        "\n",
        "* Assign the spreadsheet filename (provided above) to the variable file.\n",
        "* Pass the correct argument to pd.ExcelFile() to load the file using pandas, assigning the result to the variable xls.\n",
        "* Print the sheetnames of the Excel spreadsheet by passing the necessary argument to the print() function.\n",
        "\n",
        "\n",
        "```\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign spreadsheet filename: file\n",
        "file = 'battledeath.xlsx' #name of the spreadsheet\n",
        "\n",
        "# Load spreadsheet: xls\n",
        "xls = pd.ExcelFile(file)\n",
        "\n",
        "# Print sheet names\n",
        "print(xls.sheet_names)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHlojTUdHL98"
      },
      "source": [
        "**#3** Importing sheets from Excel files\n",
        "\n",
        "In the previous exercises, you saw that the Excel file contains two sheets, '2002' and '2004'. The next step is to import these. \n",
        "\n",
        "* Load the sheet '2004' into the DataFrame df1 using its name as a string.\n",
        "* Print the head of df1 to the shell.\n",
        "* Load the sheet 2002 into the DataFrame df2 using its index (0).\n",
        "* Print the head of df2 to the shell.\n",
        "\n",
        "```\n",
        "# Load a sheet into a DataFrame by name: df1\n",
        "df1 = xls.parse('2004') #sheetname as a string\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Load a sheet into a DataFrame by index: df2\n",
        "df2 = xls.parse(0)\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWEziVjGICf5"
      },
      "source": [
        "**4** Customizing your spreadsheet import\n",
        "\n",
        "Here, you'll parse your spreadsheets and use additional arguments to skip rows, rename columns and select only particular columns (arguments *skiprows*, *names* and *usecols*).\n",
        "\n",
        "* Parse the first sheet by index. In doing so, skip the first row of data and name the columns 'Country' and 'AAM due to War (2002)' using the argument names. The values passed to skiprows and names all need to be of type list.\n",
        "* Parse the second sheet by index. In doing so, parse only the first column with the usecols parameter, skip the first row and rename the column 'Country'. The argument passed to usecols also needs to be of type list.\n",
        "\n",
        "```\n",
        "# Parse the first sheet and rename the columns: df1\n",
        "df1 = xls.parse(0, skiprows=[1], names=['Country', 'AAM due to War (2002)'])\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "df2 = xls.parse(1, usecols=[0], skiprows=[1], names=['Country'])\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n",
        "```\n",
        "\n",
        "Note that all additional customization arguments need to need passed in a list. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isld-BFXJ_tM"
      },
      "source": [
        "---\n"
      ]
    }
  ]
}