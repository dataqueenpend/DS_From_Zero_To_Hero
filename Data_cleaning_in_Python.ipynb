{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data cleaning in Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/uNbQ/6ieJPtpJWsRSA4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataqueenpend/DS_From_Zero_To_Hero/blob/gh-pages/Data_cleaning_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBc4msYDo2XH"
      },
      "source": [
        "# Cleaning data in Python\n",
        "This notebook contains my notes and exercices solutions from DataCamp DS track. \n",
        "\n",
        "## Common Data Problems\n",
        "\n",
        "Converting data types, applying range constraints to removing future data points, removing duplicated data points to avoid double-counting. \n",
        "\n",
        "\n",
        "**Before starting any analysis on the imported data**, it is crucial to **check the data types of the columns**. We do it by using attribute ```.dtype``` or ```.info()``` method.\n",
        "\n",
        "**Checking data type information in the columns with .info() and .describe()**\n",
        "\n",
        "* Print the information of ride_sharing.\n",
        "* Use .describe() to print the summary statistics of the user_type column from ride_sharing.\n",
        "\n",
        "```\n",
        "# Print the information of ride_sharing\n",
        "print(ride_sharing.info())\n",
        "\n",
        "# Print summary statistics of user_type column\n",
        "print(ride_sharing['user_type'].describe())\n",
        "```\n",
        "\n",
        "```\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 25760 entries, 0 to 25759\n",
        "Data columns (total 9 columns):\n",
        "duration           25760 non-null object\n",
        "station_A_id       25760 non-null int64\n",
        "station_A_name     25760 non-null object\n",
        "station_B_id       25760 non-null int64\n",
        "station_B_name     25760 non-null object\n",
        "bike_id            25760 non-null int64\n",
        "user_type          25760 non-null int64\n",
        "user_birth_year    25760 non-null int64\n",
        "user_gender        25760 non-null object\n",
        "dtypes: int64(5), object(4)\n",
        "memory usage: 2.0+ MB\n",
        "None\n",
        "count    25760.000000\n",
        "mean         2.008385\n",
        "std          0.704541\n",
        "min          1.000000\n",
        "25%          2.000000\n",
        "50%          2.000000\n",
        "75%          3.000000\n",
        "max          3.000000\n",
        "Name: user_type, dtype: float64\n",
        "```\n",
        "* By looking at the summary statistics - they don't really seem to offer much description on how users are distributed along their purchase type, why do you think that is?\n",
        "\n",
        "\n",
        "\n",
        "> The user_type column has an finite set of possible values that represent groupings of data, it should be converted to category.\n",
        "\n",
        "**Converting data type with .astype attribute and checking the correction with assert statement and .dtype**\n",
        "\n",
        "* Convert user_type into categorical by assigning it the 'category' data type and store it in the user_type_cat column.\n",
        "* Make sure you converted user_type_cat correctly by using an assert statement.\n",
        "\n",
        "```\n",
        "# Print the information of ride_sharing\n",
        "print(ride_sharing.info())\n",
        "\n",
        "# Print summary statistics of user_type column\n",
        "print(ride_sharing['user_type'].describe())\n",
        "\n",
        "# Convert user_type from integer to category\n",
        "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')\n",
        "\n",
        "# Write an assert statement confirming the change\n",
        "assert ride_sharing['user_type_cat'].dtype == 'category'\n",
        "\n",
        "# Print new summary statistics \n",
        "print(ride_sharing['user_type_cat'].describe())\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydTSPD5xOQn"
      },
      "source": [
        "**Numerical values imported as strings instead of floats or ints - converting numerical data to correct data type and deleting unnecessary info with .strip() method**\n",
        "\n",
        "* Use the .strip() method to strip duration of \"minutes\" and store it in the duration_trim column.\n",
        "* Convert duration_trim to int and store it in the duration_time column.\n",
        "* Write an assert statement that checks if duration_time's data type is now an int.\n",
        "* Print the average ride duration.\n",
        "\n",
        "```\n",
        "# Strip duration of minutes\n",
        "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
        "\n",
        "# Convert duration to integer\n",
        "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
        "\n",
        "# Write an assert statement making sure of conversion\n",
        "assert ride_sharing['duration_time'].dtype == 'int'\n",
        "\n",
        "# Print formed columns and calculate average ride duration \n",
        "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
        "print(ride_sharing[['duration','duration_trim','duration_time']].mean())\n",
        "```\n",
        "\n",
        "```\n",
        "        duration duration_trim  duration_time\n",
        "0      12 minutes           12              12\n",
        "1      24 minutes           24              24\n",
        "2       8 minutes            8               8\n",
        "3       4 minutes            4               4\n",
        "4      11 minutes           11              11\n",
        "...           ...           ...            ...\n",
        "25755  11 minutes           11              11\n",
        "25756  10 minutes           10              10\n",
        "25757  14 minutes           14              14\n",
        "25758  14 minutes           14              14\n",
        "25759  29 minutes           29              29\n",
        "\n",
        "[25760 rows x 3 columns]\n",
        "duration_time    11.389053\n",
        "dtype: float64\n",
        "\n",
        "<script.py> output:\n",
        "             duration duration_trim  duration_time\n",
        "    0      12 minutes           12              12\n",
        "    1      24 minutes           24              24\n",
        "    2       8 minutes            8               8\n",
        "    3       4 minutes            4               4\n",
        "    4      11 minutes           11              11\n",
        "    ...           ...           ...            ...\n",
        "    25755  11 minutes           11              11\n",
        "    25756  10 minutes           10              10\n",
        "    25757  14 minutes           14              14\n",
        "    25758  14 minutes           14              14\n",
        "    25759  29 minutes           29              29\n",
        "    \n",
        "    [25760 rows x 3 columns]\n",
        "    duration_time    11.389053\n",
        "    dtype: float64\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhLMY-P1w7J"
      },
      "source": [
        "### Data range constraints\n",
        "\n",
        "**Converting string dtype to integer to range the values and reversing the conversion of dtype - .astype(), .loc[]**\n",
        "\n",
        "* Convert the tire_sizes column from category to 'int'.\n",
        "* Use .loc[] to set all values of tire_sizes above 27 to 27.\n",
        "* Reconvert back tire_sizes to 'category' from int.\n",
        "* Print the description of the tire_sizes.\n",
        "\n",
        "```\n",
        "# Convert tire_sizes to integer\n",
        "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
        "\n",
        "# Set all values above 27 to 27\n",
        "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
        "\n",
        "# Reconvert tire_sizes back to categorical\n",
        "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
        "\n",
        "# Print tire size description\n",
        "print(ride_sharing['tire_sizes'].describe())\n",
        "```\n",
        "\n",
        "```\n",
        "count     25760\n",
        "unique        2\n",
        "top          27\n",
        "freq      13274\n",
        "Name: tire_sizes, dtype: int64\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdPpAlq_DqE6"
      },
      "source": [
        "**Fixing incorrect dates - converting to datetime object, setting max data range to actual data with dt.date.today()**\n",
        "\n",
        "* Convert ride_date to a datetime object and store it in ride_dt column using to_datetime().\n",
        "* Create the variable today, which stores today's date by using the dt.date.today() function.\n",
        "* For all instances of ride_dt in the future, set them to today's date.\n",
        "* Print the maximum date in the ride_dt column.\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "# Convert ride_date to datetime\n",
        "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date'])\n",
        "\n",
        "# Save today's date\n",
        "today = dt.date.today()\n",
        "\n",
        "# Set all in the future to today's date\n",
        "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
        "\n",
        "# Print maximum of ride_dt column\n",
        "print(ride_sharing['ride_dt'].max())\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogSge_YMIDaj"
      },
      "source": [
        "### Uniqueness constraints\n",
        "\n",
        "**Finding duplicates with .duplicated()**\n",
        "\n",
        "* Find duplicated rows of ride_id in the ride_sharing DataFrame while setting keep to False.\n",
        "* Subset ride_sharing on duplicates and sort by ride_id and assign the results to duplicated_rides.\n",
        "* Print the ride_id, duration and user_birth_year columns of duplicated_rides in that order.\n",
        "\n",
        "```\n",
        "# Find duplicates\n",
        "duplicates = ride_sharing.duplicated(subset = 'ride_id', keep = False)\n",
        "\n",
        "# Sort your duplicated rides\n",
        "duplicated_rides = ride_sharing[duplicates].sort_values(by = 'ride_id')\n",
        "\n",
        "# Print relevant columns of duplicated_rides\n",
        "print(duplicated_rides[['ride_id','duration','user_birth_year']])\n",
        "```\n",
        "\n",
        "```\n",
        "    ride_id  duration  user_birth_year\n",
        "22       33        10             1979\n",
        "39       33         2             1979\n",
        "53       55         9             1985\n",
        "65       55         9             1985\n",
        "74       71        11             1997\n",
        "75       71        11             1997\n",
        "76       89         9             1986\n",
        "77       89         9             2060\n",
        "\n",
        "<script.py> output:\n",
        "        ride_id  duration  user_birth_year\n",
        "    22       33        10             1979\n",
        "    39       33         2             1979\n",
        "    53       55         9             1985\n",
        "    65       55         9             1985\n",
        "    74       71        11             1997\n",
        "    75       71        11             1997\n",
        "    76       89         9             1986\n",
        "    77       89         9             2060\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWcLAUvfOmb7"
      },
      "source": [
        "**Treating duplicates**\n",
        "\n",
        "Treating duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average duration, and the minimum user_birth_year for each set of incomplete duplicate rows.\n",
        "\n",
        "* Drop complete duplicates in ride_sharing and store the results in ride_dup.\n",
        "* Create the statistics dictionary which holds minimum aggregation for user_birth_year and mean aggregation for duration.\n",
        "* Drop incomplete duplicates by grouping by ride_id and applying the aggregation in statistics.\n",
        "* Find duplicates again and run the assert statement to verify de-duplication.\n",
        "\n",
        "```\n",
        "# Drop complete duplicates from ride_sharing\n",
        "ride_dup = ride_sharing.drop_duplicates()\n",
        "\n",
        "# Create statistics dictionary for aggregation function\n",
        "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
        "\n",
        "# Group by ride_id and compute new statistics\n",
        "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
        "\n",
        "# Find duplicated values again\n",
        "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
        "duplicated_rides = ride_unique[duplicates == True]\n",
        "\n",
        "# Assert duplicates are processed\n",
        "assert duplicated_rides.shape[0] == 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VuDoRwZueox"
      },
      "source": [
        "## Text and categorical data problems\n",
        "\n",
        "Categorical data can cause a lot of trouble due to it's unstructered structure. Common problems and solutions: fixing whitespace and capitalization inconsistencies in category labels, collapsing multiple categories into one, and reformatting strings for consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcacCRL9VVCc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkawY1ZNunxH"
      },
      "source": [
        "## Advanced data problems\n",
        "\n",
        "Incosistency in units of measurements (kg/pounds), missing values. Verifying that values have been added correctly and that missing values don’t negatively impact the analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2BvbA80urzr"
      },
      "source": [
        "## Record Linkage"
      ]
    }
  ]
}